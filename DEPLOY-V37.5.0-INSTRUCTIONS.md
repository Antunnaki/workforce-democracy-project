# v37.5.0 Citation Fix - EASIEST Deployment Method

## ğŸ¯ The Problem
- LLM generates many citations (e.g., [1] through [15])
- Backend only provides 3 actual source objects  
- Frontend shows broken citations

## âœ… The Solution (v37.5.0)
Pre-search sources **BEFORE** calling the LLM, so it knows exactly which sources exist and only uses those citation numbers.

---

## ğŸ“‹ EASIEST METHOD: Copy-Paste Commands

**Just copy and paste this entire block into your SSH terminal:**

```bash
cd /var/www/workforce-democracy/backend

# 1. Create backup
echo "ğŸ“¦ Creating backup..."
cp ai-service.js ai-service-BACKUP-pre-v37.5.0-$(date +%Y%m%d-%H%M%S).js

# 2. Apply startup markers (at line 19, after the header comment)
echo "ğŸ”§ Adding startup markers..."
sed -i '19 a\
console.log('\''ğŸš€ğŸš€ğŸš€ AI-SERVICE.JS v37.5.0 LOADED - CITATION FIX ACTIVE ğŸš€ğŸš€ğŸš€'\'');\
console.log('\''ğŸ“… File loaded at:'\''

, new Date().toISOString());\
console.log('\''âœ¨ Features: Pre-search sources BEFORE LLM call to prevent citation mismatches'\'');' ai-service.js

# 3. Clear Node.js module cache by adding to server.js
echo "ğŸ”§ Adding cache-clear to server.js..."
if ! grep -q "delete require.cache" server.js; then
    sed -i '/const.*= require.*ai-service/i\
// V37.5.0: Clear module cache to force fresh load\
delete require.cache[require.resolve('\''./ai-service'\'')];' server.js
fi

# 4. Restart PM2 completely
echo "ğŸ”„ Restarting PM2..."
pm2 stop backend
pm2 delete backend  
pm2 start server.js --name backend

# 5. Check logs
echo ""
echo "ğŸ“‹ Checking logs for v37.5.0 markers..."
sleep 2
pm2 logs backend --lines 20 --nostream | grep -E "ğŸš€|Server running"

echo ""
echo "âœ… If you see the rockets (ğŸš€ğŸš€ğŸš€), the file is loading!"
echo "If NOT, we need to apply the full v37.5.0 file manually."
```

---

## ğŸ” What to Look For

After running the commands above, you should see in the logs:

```
ğŸš€ğŸš€ğŸš€ AI-SERVICE.JS v37.5.0 LOADED - CITATION FIX ACTIVE ğŸš€ğŸš€ğŸš€
ğŸ“… File loaded at: 2025-11-07T...
âœ¨ Features: Pre-search sources BEFORE LLM call to prevent citation mismatches
```

### If You See the Rockets âœ…
**The startup markers are loading!** But we still need to apply the FULL v37.5.0 logic changes.

I'll provide you with the complete corrected `ai-service.js` file content that you can paste directly.

### If You DON'T See the Rockets âŒ
The file changes aren't being loaded. We'll need to debug the caching issue first.

---

## ğŸ“¥ ALTERNATIVE: Download Complete v37.5.0 File

If the above doesn't work, I can provide you with:

1. **Complete file content** - paste into nano/vim
2. **Download URL** - wget/curl a pre-made v37.5.0 file  
3. **SFTP upload** - download from this chat and upload via SFTP

**Which method would you prefer if the simple commands above don't work?**

---

## ğŸ§ª Testing After Deployment

Once v37.5.0 is active, test the chat and look for these new logs:

```
ğŸ” Pre-searching sources before LLM call...
ğŸ“š Found 3 sources to provide to LLM
âœ… Providing 3 validated sources to LLM
ğŸ¤– AI Query: "..." (context: general, sources: 3)
```

**Expected behavior:**
- LLM generates citations [1] through [3]
- Backend provides exactly 3 sources
- Frontend displays all citations as clickable
- NO more mismatches!
