#!/bin/bash
# TEST ARTICLE SCRAPER
# Purpose: Verify article scraping is working correctly

echo "ğŸ§ª ARTICLE SCRAPER TEST SCRIPT"
echo "==============================="
echo ""

# Check if article-scraper.js exists
if [ -f "/var/www/workforce-democracy/backend/article-scraper.js" ]; then
    echo "âœ… article-scraper.js exists"
else
    echo "âŒ article-scraper.js NOT FOUND"
    exit 1
fi

# Check if cheerio is installed
echo ""
echo "ğŸ“¦ Checking dependencies..."
cd /var/www/workforce-democracy/backend
if npm list cheerio > /dev/null 2>&1; then
    echo "âœ… cheerio installed"
else
    echo "âŒ cheerio NOT installed - run: npm install cheerio --save"
    exit 1
fi

# Check if integration was successful
echo ""
echo "ğŸ” Checking ai-service.js integration..."
if grep -q "article-scraper" /var/www/workforce-democracy/backend/ai-service.js; then
    echo "âœ… article-scraper import found"
else
    echo "âŒ article-scraper import NOT FOUND"
    exit 1
fi

if grep -q "scrapeMultipleArticles" /var/www/workforce-democracy/backend/ai-service.js; then
    echo "âœ… scrapeMultipleArticles call found"
else
    echo "âŒ scrapeMultipleArticles call NOT FOUND"
    exit 1
fi

# Check PM2 status
echo ""
echo "ğŸ”„ Checking PM2 status..."
pm2 list | grep backend
if [ $? -eq 0 ]; then
    echo "âœ… Backend process running"
else
    echo "âŒ Backend process NOT running"
    exit 1
fi

echo ""
echo "âœ… ALL CHECKS PASSED!"
echo ""
echo "ğŸ“‹ Next Steps:"
echo ""
echo "1. Watch the logs in real-time:"
echo "   pm2 logs backend --lines 50"
echo ""
echo "2. Make a test query (via your frontend):"
echo "   'What are the latest developments with SNAP benefits?'"
echo ""
echo "3. Look for these log messages:"
echo "   ğŸ” Pre-searching for sources before LLM call..."
echo "   ğŸ“š Found X sources - adding to context for LLM"
echo "   ğŸ“„ Scraping full article content..."
echo "   ğŸ” Starting article scraping for 5 sources..."
echo "   âœ… Scraped 2000+ chars from truthout.org"
echo "   âœ… Scraping complete: 3/5 succeeded"
echo ""
echo "4. On subsequent requests (within 24 hours):"
echo "   ğŸ’¾ Cache HIT: [article title]"
echo ""
echo "5. Verify the LLM response includes:"
echo "   â€¢ Specific dollar amounts (e.g., '$23 billion cut')"
echo "   â€¢ Direct quotes from articles"
echo "   â€¢ Detailed statistics and data"
echo "   â€¢ Multiple paragraphs with varied information"
echo ""
echo "ğŸ› If scraping fails:"
echo "   â€¢ Check: pm2 logs backend --err --lines 100"
echo "   â€¢ Look for: 'âŒ Scraping error for...'"
echo "   â€¢ Verify the source URLs are accessible"
echo ""
echo "ğŸ“Š Cache Performance:"
echo "   â€¢ First request: Scrapes 5 articles (~10-15 seconds)"
echo "   â€¢ Cached requests: Instant (< 1 second)"
echo "   â€¢ Cache duration: 24 hours per article"
echo ""
