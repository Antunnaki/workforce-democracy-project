# üóÑÔ∏è Bill Analysis Cache System

**Version:** V37.17.0-BILL-CACHE  
**Date:** January 2025  
**Status:** ‚úÖ Production Ready

---

## üéØ Overview

Smart PostgreSQL-backed caching system for AI bill analyses that **saves 99.5%+ on API costs**.

### Key Features

- ‚úÖ **Universal cache shared across ALL users** (one analysis per bill, not per user)
- ‚úÖ **Settled bills cached FOREVER** (never re-analyze passed/failed bills)
- ‚úÖ **Active bills cached for 30 days** (reduce redundant analyses)
- ‚úÖ **Keyword-based question matching** (semantic similarity for user questions)
- ‚úÖ **Cost tracking and metrics** (monitor cache hit rates and savings)
- ‚úÖ **Automatic cache cleanup** (remove expired active bill caches)

---

## üí∞ Cost Savings

### Before (No Caching):
- **50 bills** loaded per user
- **AI analysis** for each bill
- **$50-100/month** per 1,000 users

### After (PostgreSQL Caching):
- **First user** analyzes 50 bills ‚Üí **$0.50** (one-time)
- **Next 999 users** get cached results ‚Üí **$0** (FREE!)
- **Total:** $0.50/month for 1,000 users
- **Savings:** **99.5%+ reduction** üéâ

---

## üèóÔ∏è Architecture

```
User Request ‚Üí Backend API
    ‚Üì
1. Check PostgreSQL cache
    ‚îú‚îÄ HIT (90%+) ‚Üí Return cached analysis (0-50ms, FREE)
    ‚îî‚îÄ MISS (10%) ‚Üí Continue to step 2
    ‚Üì
2. Fetch bill data (Congress.gov/OpenStates)
    ‚Üì
3. Call Groq AI for analysis (~$0.0001)
    ‚Üì
4. Save to PostgreSQL cache
    ‚Üì
5. Return analysis to user
```

---

## üìä Database Schema

### Table 1: `bills_cache`
Stores AI bill analyses (one per bill, shared across all users)

| Column | Type | Description |
|--------|------|-------------|
| `bill_id` | VARCHAR(100) | Unique bill ID (e.g., "hr1234-118") |
| `bill_title` | TEXT | Bill title |
| `ai_analysis_full` | TEXT | Complete AI analysis (JSON) |
| `labor_impact` | TEXT | Das Kapital framework: Impact on workers |
| `economic_framework` | TEXT | Materialist economic analysis |
| `keywords` | TEXT[] | Keywords for semantic matching |
| `expires_at` | TIMESTAMP | NULL = never expires (settled bills) |
| `cache_hits` | INTEGER | Times this cache was used (savings metric!) |
| `groq_api_cost` | DECIMAL | Cost of this analysis |

### Table 2: `bill_questions_cache`
Stores user questions and AI answers (keyword-based matching)

| Column | Type | Description |
|--------|------|-------------|
| `bill_id` | VARCHAR(100) | Link to bill |
| `question_text` | TEXT | Original question |
| `question_keywords` | TEXT[] | Extracted keywords |
| `answer_text` | TEXT | AI-generated answer |
| `asked_count` | INTEGER | Times this question was asked |
| `groq_api_cost` | DECIMAL | Cost of this answer |

### Table 3: `cache_metrics`
Daily performance tracking

| Column | Type | Description |
|--------|------|-------------|
| `date` | DATE | Date |
| `total_requests` | INTEGER | Total API requests |
| `cache_hits` | INTEGER | Requests served from cache |
| `cache_hit_rate` | DECIMAL | Hit rate percentage |
| `total_cost_saved` | DECIMAL | Money saved by caching |

---

## üöÄ Setup Instructions

### Step 1: Install PostgreSQL

```bash
# Ubuntu/Debian
sudo apt-get install postgresql-14

# macOS
brew install postgresql@14

# Start PostgreSQL
sudo service postgresql start  # Linux
brew services start postgresql@14  # macOS
```

### Step 2: Run Setup Script

```bash
cd backend/scripts
chmod +x setup-bill-cache-database.sh
./setup-bill-cache-database.sh
```

The script will:
1. Create database `workforce_democracy`
2. Create tables (`bills_cache`, `bill_questions_cache`, `cache_metrics`)
3. Create views (`popular_bills`, `popular_questions`, `cache_performance_summary`)
4. Create functions (`extract_keywords`, `keyword_match_score`, etc.)

### Step 3: Configure Environment Variables

Add to `backend/.env`:

```bash
# PostgreSQL Database
DB_USER=postgres
DB_NAME=workforce_democracy
DB_HOST=localhost
DB_PORT=5432
DB_PASSWORD=your_password_here

# Groq API (for AI analysis)
GROQ_API_KEY=your_groq_api_key_here
```

### Step 4: Start Backend Server

```bash
cd backend
npm install pg  # Install PostgreSQL client
npm start
```

---

## üìñ Usage Examples

### Example 1: Analyze a Bill (First Time)

```bash
curl -X POST http://localhost:3001/api/ai/bills/analyze \
  -H 'Content-Type: application/json' \
  -d '{
    "bill": {
      "id": "hr1234-118",
      "title": "Affordable Housing Act",
      "level": "federal",
      "status": "Introduced"
    }
  }'
```

**Response:**
```json
{
  "success": true,
  "bill_id": "hr1234-118",
  "cached": false,
  "analysis": { /* AI analysis */ }
}
```

**Cost:** ~$0.0001 (Groq API call)

### Example 2: Analyze Same Bill (Second User)

Same request as above.

**Response:**
```json
{
  "success": true,
  "bill_id": "hr1234-118",
  "cached": true,
  "cache_hits": 42,
  "analysis": { /* Cached analysis */ }
}
```

**Cost:** $0 (FREE!)  
**Savings:** $0.0001 √ó 42 hits = **$0.0042 saved**

### Example 3: Ask a Question About a Bill

```bash
curl -X POST http://localhost:3001/api/ai/bills/chat \
  -H 'Content-Type: application/json' \
  -d '{
    "bill": {"id": "hr1234-118", "title": "Affordable Housing Act"},
    "question": "How does this affect teachers?"
  }'
```

**First User:**
- Calls Groq API
- Caches Q&A with keywords: `['affect', 'teachers']`
- **Cost:** $0.00005

**Second User asks:** "What's the impact on educators?"
- Keywords: `['impact', 'educators']`
- **Semantic match** (teachers ‚âà educators): 75% similarity
- Returns cached answer
- **Cost:** $0 (FREE!)

---

## üìä Monitoring & Analytics

### View Cache Performance

```sql
SELECT * FROM cache_performance_summary;
```

| date | total_requests | cache_hits | cache_hit_rate | total_cost_saved |
|------|----------------|------------|----------------|------------------|
| 2025-01-15 | 1000 | 920 | 92.00% | $8.50 |

### View Most Popular Bills

```sql
SELECT * FROM popular_bills LIMIT 10;
```

| bill_id | bill_title | cache_hits | total_savings |
|---------|-----------|------------|---------------|
| hr1234-118 | Affordable Housing Act | 457 | $0.0580 |
| s5678-118 | Medicare Expansion | 342 | $0.0434 |

### View Most Asked Questions

```sql
SELECT * FROM popular_questions LIMIT 10;
```

| bill_id | question_text | asked_count | total_savings |
|---------|--------------|-------------|---------------|
| hr1234-118 | How does this affect teachers? | 89 | $0.0045 |
| hr1234-118 | What's the cost? | 67 | $0.0034 |

---

## üßπ Maintenance

### Clean Up Expired Caches (Automatic)

The backend automatically runs cleanup every 24 hours.

**Manual cleanup:**

```sql
SELECT cleanup_expired_caches();
```

### Reset All Caches (Danger!)

```sql
TRUNCATE bills_cache, bill_questions_cache, cache_metrics RESTART IDENTITY CASCADE;
```

‚ö†Ô∏è **Warning:** This deletes ALL cached data!

---

## üêõ Troubleshooting

### Issue: "Cannot connect to database"

**Cause:** PostgreSQL not running or wrong credentials

**Fix:**
```bash
# Check if PostgreSQL is running
sudo service postgresql status

# Restart PostgreSQL
sudo service postgresql restart

# Test connection
psql -U postgres -d workforce_democracy -c "SELECT NOW();"
```

### Issue: "Slow queries"

**Cause:** Missing indexes or large dataset

**Fix:**
```sql
-- Rebuild indexes
REINDEX TABLE bills_cache;
REINDEX TABLE bill_questions_cache;

-- Analyze tables for query optimization
ANALYZE bills_cache;
ANALYZE bill_questions_cache;
```

### Issue: "Cache hit rate too low (<70%)"

**Possible causes:**
1. Many unique bills (expected initially)
2. Users asking very different questions
3. Active bills expiring (30-day TTL)

**Monitoring:**
```sql
SELECT 
    date,
    cache_hit_rate,
    cache_hits,
    cache_misses
FROM cache_metrics
ORDER BY date DESC
LIMIT 7;
```

---

## üîê Security Best Practices

1. **Never commit `.env` file** (contains DB password)
2. **Use strong PostgreSQL password** (12+ characters, mixed case, numbers, symbols)
3. **Limit database access** (only backend server should connect)
4. **Regular backups**:
   ```bash
   pg_dump -U postgres workforce_democracy > backup.sql
   ```
5. **Encrypt sensitive data** (user contexts, voting history - TODO)

---

## üìà Performance Targets

| Metric | Target | Actual |
|--------|--------|--------|
| Cache Hit Rate | 80-90% | TBD |
| Cached Response Time | <100ms | TBD |
| DB Response Time | <200ms | TBD |
| Groq API Response Time | <2000ms | TBD |
| Cost Per 1,000 Users | <$1/month | TBD |

---

## üöß Future Enhancements

- [ ] **Amendment detection** (auto-invalidate cache when bills are amended)
- [ ] **Word embeddings** (upgrade from keyword matching to vector similarity)
- [ ] **Multi-language support** (cache analyses in different languages)
- [ ] **Personalized analyses** (cache user-specific contexts)
- [ ] **GraphQL API** (more efficient data fetching)

---

## üìö Additional Documentation

- **Database Schema:** `bill-analysis-cache-schema.sql`
- **API Endpoints:** `backend/routes/ai-bills-routes.js`
- **Keyword Matcher:** `backend/utils/keyword-matcher.js`
- **Cache Manager:** `backend/utils/bill-cache.js`

---

## ü§ù Contributing

Questions or improvements? Open an issue or submit a PR!

---

**Built with ‚ù§Ô∏è for democracy, transparency, and cost-effective civic engagement.**
